{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Assessment 2\n",
    "#### Student Name: Prashasti Garg\n",
    "#### Student ID: 31901611\n",
    "\n",
    "Date: 08/02/2021\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3.7.9 and Jupyter notebook\n",
    "\n",
    "Libraries used: please include the main libraries you used in your assignment here, e.g.,:\n",
    "* `pandas` (for data manipulation and interpretation)\n",
    "* `numpy` (for working in domain of linear algebra)\n",
    "* `nltk` (for sentimental analyses of text)\n",
    "* `math` (for solving mathematical functions)\n",
    "* `matplotlib.pyplot` (for plotting the graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIRTY DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "- The file has 16 columns, out of which coupon_discount, delivery_charges and the ordered quantity values in the shopping_cart attribute are always correct.\n",
    "- Remaining columns thus can have anolamalies needs which needs to be investigated.\n",
    "- Each row can only have one anomaly.\n",
    "\n",
    "1. order_id          : A unique id for each order\n",
    "2. customer_id       : A unique id for each customer\n",
    "3. date              : The date the order was made, given in YYYY-MM-DD format\n",
    "4. nearest_warehouse : A string denoting the name of the nearest warehouse to the customer\n",
    "5. shopping_cart     : A list of tuples representing the order items: first element of the tuple is the item ordered, and the                          second element is the quantity ordered for such item.\n",
    "6. order_price       : A float denoting the order price in AUD. The order price is the price of items before any discounts                            and/or delivery charges are applied.\n",
    "7. delivery_charges  : A float representing the delivery charges of the order\n",
    "8. customer_lat      : Latitude of the customer’s location\n",
    "9. customer_long     : Longitude of the customer’s location\n",
    "10. coupon_discount  : An integer denoting the percentage discount to be applied to the order_price\n",
    "11. order_total      : A float denoting the total of the order in AUD after all discounts and/or delivery charges are applied.\n",
    "12. season           : A string denoting the season in which the order was placed. Refer to this link for details about how                            seasons are defined\n",
    "13. is_expedited_delivery : A boolean denoting whether the customer has requested an expedited delivery\n",
    "14. distance_to_nearest_warehouse : A float representing the arc distance, in kilometres, between the customer and the nearest                                    warehouse to him/her (radius of earth: 6378 KM)\n",
    "15. latest_customer_review : A string representing the latest customer review on his/her most recent order\n",
    "16. is_happy_customer : A boolean denoting whether the customer is a happy customer or had an issue with his/her last order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dirty file is read using pandas\n",
    "dirty_file= pd.read_csv(r'.\\dirty_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warehouse file is read using pandas\n",
    "warehouse_file = pd.read_csv(r'.\\warehouses.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the conscise summary of dataframe in dirty file\n",
    "dirty_file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.describe() summarises the statistics pertaining to the DataFrame columns\n",
    "dirty_file.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .describe() has shown that few column has an outlier ie, they are very distinctive to the other remaining values in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .describe(include=['O']) shows that nearest_warehouse and season column has 5 and 8 respectively unique values where they must have 3 and 4 respective values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_check = [False for i in range(len(dirty_file))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting the dates\n",
    "- Dates in the column date, needs to be investigated, it should be in the correct format with DD/MM/YYYY.\n",
    "- date is first splitted with \"-\".\n",
    "- Lastly, using string formatting, date is formatted into correct form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirty_file is iterated where i is the row number of file\n",
    "for i, j in dirty_file.iterrows():\n",
    "    # date in the file is splitted along \"-\"\n",
    "    # date whose first indice is year is send through if and it would be formatted in correct form\n",
    "    # date is formatted\n",
    "    if  j['date'].split('-')[0] != '2019':\n",
    "        defect_split = j['date'].replace(\" \", \"-\").replace(\"/\",\"-\").split(\"-\")\n",
    "        # all the anomalies in the date column in corrected and stored in the column\n",
    "        dirty_file.loc[i,\"date\"] = \"{}-{}-{}\".format(defect_split[2],defect_split[0],defect_split[1])\n",
    "        column_check[i] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the season with respect to date\n",
    "- Months specify different season:\n",
    " * `Spring` - September, October, November\n",
    " * `Summer` - December, January, February\n",
    " * `Autumn` - March, April, May\n",
    " * `Winter` - June, July, August\n",
    "- In the season column, it needs to be investigated whether the season matches with its ccorresponding month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in dirty_file.iterrows():\n",
    "    date_split =  j['date'].split('-')\n",
    "    # if condition for months who lie with the range of Spring season but has wrong season specified\n",
    "    if int(date_split[1]) > 8 and int(date_split[1]) < 12 and j['season'].lower() != 'spring':\n",
    "        dirty_file.loc[i,'season'] = 'Spring'\n",
    "        column_check[i] = True\n",
    "        \n",
    "    # if condition for months who lie with the range of Summer season but has wrong season specified\n",
    "    if (int(date_split[1]) < 3 or int(date_split[1]) == 12) and j['season'].lower() != 'summer':\n",
    "        dirty_file.loc[i,'season'] = 'Summer'\n",
    "        column_check[i] = True\n",
    "        \n",
    "    # if condition for months who lie with the range of Autumn season but has wrong season specified\n",
    "    if int(date_split[1]) > 2 and int(date_split[1]) < 6 and j['season'].lower() != 'autumn':\n",
    "        dirty_file.loc[i,'season'] = 'Autumn'\n",
    "        column_check[i] = True\n",
    "        \n",
    "    # if condition for months who lie with the range of Winter season but has wrong season specified\n",
    "    if int(date_split[1]) > 5 and int(date_split[1]) < 9 and j['season'].lower() != 'winter':\n",
    "        dirty_file.loc[i,'season'] = 'Winter'\n",
    "        column_check[i] = True\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the values of season and warehouses\n",
    "- Season and warehouse have limited values, it may include some anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkes the values in season column with their counts\n",
    "dirty_file.season.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the above cell, we investigated that Season column has no anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.nearest_warehouse.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nearest_warehouse has an anolamy in name of object, which needs to corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.nearest_warehouse.replace({'nickolson': 'Nickolson', 'thompson':'Thompson'}, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.nearest_warehouse.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting the names of items in shopping_cart \n",
    "- In the shopping_cart, there are 10 items.\n",
    "- We need to iterate through column to find the names of items are unique.\n",
    "- We found that there are many case realted problem in names of shopping cart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using .replace() we replaced the case related problem in shopping_cart items\n",
    "correct_items = {\n",
    "    \"ALCON 10\": \"Alcon 10\",\n",
    "    \"CANDLE INFERNO\": \"Candle Inferno\",\n",
    "    \"IASSIST LINE\": \"iAssist Line\",\n",
    "    \"ISTREAM\": \"iStream\",\n",
    "    \"LUCENT 330S\": \"Lucent 330S\",\n",
    "    \"OLIVIA X460\": \"Olivia x460\",\n",
    "    \"PEARTV\": \"pearTV\",\n",
    "    \"THUNDER LINE\": \"Thunder line\",\n",
    "    \"TOSHIKA 750\": \"Toshika 750\",\n",
    "    \"universe note\": \"Universe Note\",\n",
    "    \"alcon 10\": \"Alcon 10\",\n",
    "    \"candle inferno\": \"Candle Inferno\",\n",
    "    \"iassist line\": \"iAssist Line\",\n",
    "    \"istream\": \"iStream\",\n",
    "    \"lucent 330s\": \"Lucent 330S\",\n",
    "    \"olivia x460\": \"Olivia x460\",\n",
    "    \"peartv\": \"pearTV\",\n",
    "    \"thunder line\": \"Thunder line\",\n",
    "    \"toshika 750\": \"Toshika 750\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in dirty_file.iterrows():\n",
    "    for x in correct_items.items():\n",
    "        j.shopping_cart = j.shopping_cart.replace(x[0], x[1])\n",
    "    dirty_file.loc[i, 'shopping_cart'] = j.shopping_cart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the order_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The order_price is the total of all items with their ordered quantity.\n",
    "- The value of order_price needs to investigated as the amount of each item is different, therefore using array matrix, price of each item can be found.\n",
    "- Simultaneously, the order_price can be checked.\n",
    "- The items in shopping_carthas limited values, that is 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCart(cart):\n",
    "    cart_list = []\n",
    "    for i in cart.strip(\"[]\").split(\", (\"):\n",
    "        temp = i.strip(\"()\").split(\", \")\n",
    "        item = temp[0].strip(\"''\").lower()\n",
    "        qty = int(temp[1])\n",
    "        cart_list.append((item, qty))\n",
    "    return np.array(cart_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list = []\n",
    "for i, j in dirty_file.iterrows():\n",
    "    items = getCart(j.shopping_cart)\n",
    "    item_list += list(items[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_set = set(item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(item_set)# item in shopping_cart is investigated  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary is created to store the items and its corresponding quantity of each row\n",
    "item_dict = {}\n",
    "for i in item_set:\n",
    "    item_dict[i] = 0 #initially value in dictionary is set as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopping_coeff = []\n",
    "for i, j in dirty_file.iterrows():\n",
    "    if column_check[i]:\n",
    "        for x in item_dict:\n",
    "            item_dict[x] = 0 #values in dictionary is emptied to iterate to next row\n",
    "    \n",
    "        items = getCart(j.shopping_cart)\n",
    "            \n",
    "        for x in items:\n",
    "            item_dict[x[0]] = x[1] #quantity of items in shopping_cart of each row has been added in dictionary\n",
    "        \n",
    "        temp = list(item_dict.values()) #it consists of one row which contains the quantity\n",
    "        temp.append(int(j.order_price)) # the order_price has been also added in matrix \n",
    "        shopping_coeff.append(temp)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_shopping = np.array(shopping_coeff, dtype=\"float64\") #list is converted to np.array\n",
    "np_shopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np_shopping[:10, :10] #rows,column\n",
    "x # only quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np_shopping[:10, 10]\n",
    "#only the order_price of each shopping_cart\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = np.linalg.solve(x, y) #sparse matrix is solved\n",
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded = np.round(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in enumerate(item_dict):\n",
    "    item_dict[k] = rounded[i] # dictionary of all items in shopping_cart with their respective value of 1 quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in dirty_file.iterrows():\n",
    "    order_price = 0\n",
    "    items = getCart(j.shopping_cart)\n",
    "    for item in items:\n",
    "        order_price += int(item[1]) * item_dict[item[0]]\n",
    "    # order_price calculated above if does not matches with the order_price of dirty_file, then update the value in file \n",
    "    if order_price != j.order_price:\n",
    "        column_check[i] = True\n",
    "        dirty_file.loc[i, 'order_price'] = order_price\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the order_total\n",
    "- order_total is the sum of order_price which may get reducted with coupon_discount.\n",
    "- delivery_charges are added in the last after coupon_discount.\n",
    "- Therefore, using an equation, order_total can be checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in dirty_file.iterrows():\n",
    "    # equation to check the order_total\n",
    "    price = round((j['order_price'] * ((100 - j['coupon_discount'])/100)) + j['delivery_charges'], 2)\n",
    "    # whichever row in order_total doesnot match with the price calculated needs to updated\n",
    "    if price != j['order_total']:        \n",
    "        dirty_file.loc[i, 'order_total'] = price\n",
    "        column_check[i] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Checking is_happy_customer\n",
    "- is_happy_customer contains boolean value.\n",
    "- It can be examed with the feedback of customers in latest_customer_review column.\n",
    "- Using nltk.SentimentIntensityAnalyzer, values in is_happy_customer can be checked.\n",
    "- The review with the polarity score of 'compound' of 0.05 or greater is considered True and remaining False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examines the boolean value in is_happy_customer\n",
    "dirty_file.is_happy_customer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in dirty_file.iterrows():\n",
    "    review = j.latest_customer_review\n",
    "    senti_review = senti.polarity_scores(review)\n",
    "    temp = senti_review['compound']\n",
    "    if temp >= 0.05 and j['is_happy_customer'] != True:\n",
    "        dirty_file.loc[i,'is_happy_customer'] = True\n",
    "        column_check[i] = True\n",
    "    elif temp < 0.05 and j['is_happy_customer'] == True:\n",
    "        dirty_file.loc[i,'is_happy_customer'] = False\n",
    "        column_check[i] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.is_happy_customer.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the customer_lat\n",
    "- customer_lat includes the latitude of the customer.\n",
    "- The electronics store is situated in Melbourne, Australia. \n",
    "- Thus all the latitudes which fall ouside of the city needs to fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dictionary is created which stores the latitude and longitude of the warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse_latlong ={}\n",
    "for i in range(len(warehouse_file)):  \n",
    "    #name of the warehouse is the key and latitude and longitude are the values\n",
    "    warehouse_latlong[warehouse_file.loc[i, 'names']] = (warehouse_file.loc[i, 'lat'], warehouse_file.loc[i, 'lon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking whether the latitude of customer are negative or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in dirty_file.iterrows():\n",
    "    j = dirty_file.loc[i]\n",
    "    if j.customer_lat > 0:\n",
    "        dirty_file.loc[i,'customer_lat'] = -1 * j.customer_lat\n",
    "        column_check[i] = True       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using boxplot to find the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "bp = dirty_file.boxplot(column = 'customer_lat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finding out the rows whose latitudes have anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_lat = []\n",
    "for i,j in dirty_file.iterrows():\n",
    "    m = j.customer_lat\n",
    "    if not (m <= -37.79 and m >= -37.84):\n",
    "        i_lat.append(i)\n",
    "        column_check[i] = True       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_lat(dist, lon1, lat2, lon2):\n",
    "    # lat2, lon2 = warehouse's coordinates\n",
    "    radius = 6378\n",
    "    \n",
    "    a = -0.5 * math.sin(math.radians(lat2))\n",
    "    b = (math.sin(math.radians(lon2-lon1)/2) ** 2 - 0.5) * math.cos(math.radians(lat2))\n",
    "    x_squa = math.tan(dist / radius / 2) ** 2\n",
    "    phi = math.atan2(b,a)\n",
    "    A = math.sqrt(a **2 + b**2)\n",
    "    \n",
    "    s1 = round((-phi - math.asin(((x_squa / (1 - x_squa)) - 0.5) / A) - math.pi) / math.pi * 180, 7)\n",
    "    s2 = round((-phi + math.asin(((x_squa / (1 - x_squa)) - 0.5)/A)) / math.pi * 180 , 7)\n",
    "    return s1,s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in dirty_file.iterrows():\n",
    "    if i in i_lat:\n",
    "        j = dirty_file.loc[i]\n",
    "        lat_cal = haversine_lat(j.distance_to_nearest_warehouse, j.customer_long, warehouse_latlong[j.nearest_warehouse][0], warehouse_latlong[j.nearest_warehouse][1])\n",
    "        if j['customer_lat'] != lat_cal[0] and j['customer_lat'] != lat_cal[1]:\n",
    "            dirty_file.loc[i, 'customer_lat'] = round(lat_cal[0],7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "bp = dirty_file.boxplot(column = 'customer_lat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now there is no outlier in boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "dirty_file['customer_lat'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the customer_long\n",
    "- We need to find the anomalies in customer_long.\n",
    "- The electonic shope is situated in Melbourne, Australia.\n",
    "- Thus all latitudes which fall outside of the city needs to be fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finding the outliers in longitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "bp = dirty_file.boxplot(column = 'customer_long')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finding out the indices of row which have anomaly in customer_latitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_lon = []\n",
    "for i,j in dirty_file.iterrows():\n",
    "    m = j.customer_long\n",
    "    if not (m >= 144.93 and m <= 145.1):\n",
    "        i_lon.append(i)\n",
    "        column_check[i] = True       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_lon(dist, lat1, lat2, lon2):\n",
    "    #lat1, lon2 = customer's coordinates\n",
    "    # lat2, lon2 = warehouse's coordinates\n",
    "    radius = 6378\n",
    "    \n",
    "    x_squa = math.tan(dist / radius / 2) ** 2\n",
    "    top = x_squa * ((x_squa / (1 + x_squa) - math.sin(math.radians(lat1 - lat2) / 2) ** 2) ** 2)\n",
    "    bot = math.cos(math.radians(lat2)) * math.cos(math.radians(lat1))\n",
    "    \n",
    "    s1 = round(2 * math.asin(math.sqrt(top/bot)) / math.pi * 180 + lon2, 7)\n",
    "    s2 = round(2 * math.asin(- math.sqrt(top/bot)) / math.pi * 180 + lon2, 7)\n",
    "    \n",
    "    return s1, s2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in dirty_file.iterrows():\n",
    "    if i in i_lon:\n",
    "        j = dirty_file.loc[i]\n",
    "        lon_cal = haversine_lon(j.distance_to_nearest_warehouse, j.customer_lat, warehouse_latlong[j.nearest_warehouse][0], warehouse_latlong[j.nearest_warehouse][1])\n",
    "        if j['customer_long'] != lon_cal[0] and j['customer_long'] != lon_cal[1]:\n",
    "            dirty_file.loc[i, 'customer_long'] = round(lon_cal[0],7)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "bp = dirty_file.boxplot(column = 'customer_long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "dirty_file['customer_long'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the distance_to_nearest_warehouse\n",
    "- In this column, we need to find the distance with each warehouse in order to find the nearest warehouse to the customer.\n",
    "- The distance_to_neraest_warehouse will them need to be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    radius_of_earth = 6378\n",
    "\n",
    "    cust_lat = math.radians(lat1)\n",
    "    cust_long = math.radians(lon1)\n",
    "    warehouse_lat = math.radians(lat2)\n",
    "    warehouse_long = math.radians(lon2)\n",
    "\n",
    "    dlat = cust_lat - warehouse_lat\n",
    "    dlon = cust_long - warehouse_long\n",
    "\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(cust_lat) * math.cos(warehouse_lat) * math.sin(dlon / 2)**2\n",
    "    distance = radius_of_earth * (2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))) \n",
    "    \n",
    "    return round(distance,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in dirty_file.iterrows():\n",
    "    #to store the minimum value, therefore infinity is stored, which is greater than all\n",
    "    minDistance = math.inf\n",
    "    nearestWarehouse = math.inf\n",
    "    for warehouse in warehouse_latlong:\n",
    "        distance = haversine_distance(j.customer_lat, j.customer_long, warehouse_latlong[warehouse][0], warehouse_latlong[warehouse][1])\n",
    "        if distance < minDistance:\n",
    "            minDistance = distance\n",
    "            nearestWarehouse = warehouse            \n",
    "    if minDistance < j.distance_to_nearest_warehouse and j.nearest_warehouse == nearestWarehouse:\n",
    "        dirty_file.loc[i, 'distance_to_nearest_warehouse'] = distance\n",
    "        column_check[i] = True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "dirty_file['distance_to_nearest_warehouse'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.loc[94, 'distance_to_nearest_warehouse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file['distance_to_nearest_warehouse'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the nearest_warehouse\n",
    "- nearest_warehouse column needs to check the warehouse name corresponding to the distance.\n",
    "- Therefore, all the values which have anomaly needs to be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in dirty_file.iterrows():\n",
    "        j = dirty_file.loc[i]\n",
    "        for warehouse in warehouse_latlong:\n",
    "            distance = haversine_distance(j.customer_lat, j.customer_long, warehouse_latlong[warehouse][0], warehouse_latlong[warehouse][1])\n",
    "            if j.distance_to_nearest_warehouse == distance and j.nearest_warehouse != warehouse:\n",
    "                dirty_file.loc[i,'nearest_warehouse'] = warehouse\n",
    "                column_check[i] = True \n",
    "                break        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.to_csv(r'./31901611_dirty_data_solution.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For finding the seasons of Australia all over the year.\n",
    " * [http://www.bom.gov.au/climate/glossary/seasons.shtml]\n",
    "- For finding the haversine distance formula to calculalte distance_to_nearest_warehouse.\n",
    " * [https://stackoverflow.com/questions/4913349/haversine-formula-in-python-bearing-and-distance-between-two-gps-points]\n",
    "- For finding the latitude and longitude of Melbourne, Austrlaia.\n",
    " * [https://en.wikipedia.org/wiki/Module:Location_map/data/Australia_Victoria_Melbourne_metropolitan_area_complete]\n",
    " * [https://www.google.com/search?q=melbourne+latitude+and+longitude+range&oq=me&aqs=chrome.2.69i59l3j69i57j69i60l2j69i61j69i65.1753j0j7&sourceid=chrome&ie=UTF-8]\n",
    "- For solving the \"math domain error\".\n",
    " * [https://stackoverflow.com/questions/15890503/valueerror-math-domain-error]\n",
    "- For understanding the boxplot.\n",
    " * [https://towardsdatascience.com/understanding-boxplots-5e2df7bcbd51]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dirty_data.csv, it included some syntactic and semantic anomalies, which has been fixed. Also a new 31901611_dirty_data_solution.csv has been created which does not have any anomaly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISSING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missing_data.csv has 16 columns. It has missing values in some column, which is called as Coverage Anomaly. We need to  investigate the file in order to find the columns which has anomaly.\n",
    "\n",
    "1. order_id          : A unique id for each order\n",
    "2. customer_id       : A unique id for each customer\n",
    "3. date              : The date the order was made, given in YYYY-MM-DD format\n",
    "4. nearest_warehouse : A string denoting the name of the nearest warehouse to the customer\n",
    "5. shopping_cart     : A list of tuples representing the order items: first element of the tuple is the item ordered, and the                          second element is the quantity ordered for such item.\n",
    "6. order_price       : A float denoting the order price in AUD. The order price is the price of items before any discounts                            and/or delivery charges are applied.\n",
    "7. delivery_charges  : A float representing the delivery charges of the order\n",
    "8. customer_lat      : Latitude of the customer’s location\n",
    "9. customer_long     : Longitude of the customer’s location\n",
    "10. coupon_discount  : An integer denoting the percentage discount to be applied to the order_price\n",
    "11. order_total      : A float denoting the total of the order in AUD after all discounts and/or delivery charges are applied.\n",
    "12. season           : A string denoting the season in which the order was placed. Refer to this link for details about how                            seasons are defined\n",
    "13. is_expedited_delivery : A boolean denoting whether the customer has requested an expedited delivery\n",
    "14. distance_to_nearest_warehouse : A float representing the arc distance, in kilometres, between the customer and the nearest                                    warehouse to him/her (radius of earth: 6378 KM)\n",
    "15. latest_customer_review : A string representing the latest customer review on his/her most recent order\n",
    "16. is_happy_customer : A boolean denoting whether the customer is a happy customer or had an issue with his/her last order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file = pd.read_csv(r'.\\missing_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .head() displays the first five rows of the file\n",
    "missing_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We need to calculate the number of missing values in each column. Thus .isnull().sum() gives the sum of all null values in every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- missing_file has 8 columns which includes 10 missing values each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing the missing values in season column\n",
    "- The missing_file includes 10 missing values in season column.\n",
    "- Months specify different season:\n",
    " * `Spring` - September, October, November\n",
    " * `Summer` - December, January, February\n",
    " * `Autumn` - March, April, May\n",
    " * `Winter` - June, July, August\n",
    " - By maping the month in date column with the season mentioned above, can we impute the missing value in season column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file.season.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding all the indices of the row which has missing value in season column\n",
    "null_season = missing_file[missing_file['season'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in null_season:\n",
    "    j = missing_file.loc[i]\n",
    "    # date is split to find the month which will be mapped to find the season\n",
    "    date_split =  j['date'].split('-')\n",
    "    \n",
    "    #if the specified moth falls under the section of particular season, the missing value will be imputed\n",
    "    if int(date_split[1]) > 8 and int(date_split[1]) < 12:\n",
    "        missing_file.loc[i,'season'] = 'Spring'\n",
    "        \n",
    "    if int(date_split[1]) < 3 or int(date_split[1]) == 12: \n",
    "        missing_file.loc[i,'season'] = 'Summer'\n",
    "            \n",
    "    if int(date_split[1]) > 2 and int(date_split[1]) < 6:\n",
    "        missing_file.loc[i,'season'] = 'Autumn'\n",
    "            \n",
    "    if int(date_split[1]) > 5 and int(date_split[1]) < 9: \n",
    "        missing_file.loc[i,'season'] = 'Winter'\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file.season.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file.season.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "missing_file['season'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing the missing values in nearest_warehouse\n",
    "- nearest_warehouse has 10 missing values.\n",
    "- By finding the distance between customer's coordinated and warehouse's coordinates, nearest_warehouse can be imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file.nearest_warehouse.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the rows of the column which has missing values.\n",
    "null_warehouse = missing_file[missing_file['nearest_warehouse'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in null_warehouse:\n",
    "    j = missing_file.loc[i]\n",
    "    for warehouse in warehouse_latlong:\n",
    "            #finding the distance using customer_lat, customer_long and warehouse's lat amd warehouse'lon\n",
    "            distance = haversine_distance(j.customer_lat, j.customer_long, warehouse_latlong[warehouse][0], warehouse_latlong[warehouse][1])\n",
    "            #if calculated distance matches with the distance_to_nearest_warehouse, value will be imputed in nearest_warehouse\n",
    "            if j.distance_to_nearest_warehouse == distance:\n",
    "                missing_file.loc[i,'nearest_warehouse'] = warehouse\n",
    "                break        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the count of each warehouse\n",
    "missing_file.nearest_warehouse.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "missing_file['nearest_warehouse'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the null values in this column\n",
    "missing_file.nearest_warehouse.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing the missing values of distance_to_nearest_warehouse\n",
    "- distance_to_nearest_warehouse contains 10 missing values.\n",
    "- Using the nearest_warehouse, can we get the warehouse which is close to the customer, and then using the coordinates of customer and warehouse we can find the distance using haversine distance which has been defined above as haversine_distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the indices of row which has missing values in distance_to_nearest_warehouse column\n",
    "null_distance = missing_file[missing_file['distance_to_nearest_warehouse'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in null_distance:\n",
    "    j = missing_file.loc[i]\n",
    "    #finding the distance using customer_lat, customer_long and warehouse's lat amd warehouse'lon\n",
    "    distance_calulate = haversine_distance(j.customer_lat, j.customer_long, warehouse_latlong[j.nearest_warehouse][0], warehouse_latlong[j.nearest_warehouse][1])\n",
    "    missing_file.loc[i, 'distance_to_nearest_warehouse'] = distance_calulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "missing_file['distance_to_nearest_warehouse'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the null values in this column\n",
    "missing_file.distance_to_nearest_warehouse.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing the missing values of customer_lat\n",
    "- customer_lat column has 10 missing values.\n",
    "- Using a formula which has defined under haversine_lat is called to find the customer_lat.\n",
    "- It requires the distance between customer and warehouse which is defined by distance_to_nearest_warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_lat(dist,lon1,lat2,lon2):\n",
    "    #dist = distance_to_nearest_warehouse\n",
    "    #lat1,lat2 = customer's coordinates\n",
    "    #lat2, lon2 = warehouse's coordinates\n",
    "    \n",
    "    radius = 6378 #Km\n",
    "    \n",
    "    a = -0.5 * math.sin(math.radians(lat2))\n",
    "    b = (math.sin(math.radians(lon1-lon2)/2) ** 2 - 0.5) * math.cos(math.radians(lat2))\n",
    "    x_squa = math.tan(dist / radius / 2) ** 2\n",
    "    phi = math.atan2(b,a) #radius\n",
    "    A = math.sqrt(a **2 + b**2)\n",
    "    \n",
    "    s1 = round((-phi - math.asin(((x_squa / (1 - x_squa)) - 0.5) / A) - math.pi) / math.pi * 180, 7)\n",
    "    s2 = round((-phi + math.asin(((x_squa / (1 - x_squa)) - 0.5) / A)) / math.pi * 180 , 7)\n",
    "    return s1,s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the indices of row which has missing value for customer_lat.\n",
    "null_lat = missing_file[missing_file['customer_lat'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in null_lat:\n",
    "    j = missing_file.loc[i]\n",
    "    #finding the customer_lat using distance_to_nearest_warehouse, customer_long, warehouse's lat, warehouse's lon\n",
    "    lat_cal = haversine_lat(j.distance_to_nearest_warehouse, j.customer_long, warehouse_latlong[j.nearest_warehouse][0], warehouse_latlong[j.nearest_warehouse][1])\n",
    "    missing_file.loc[i, 'customer_lat'] = lat_cal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "bp = missing_file.boxplot(column = 'customer_lat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the missing values in this column\n",
    "missing_file.customer_lat.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing the missing values of customer_long\n",
    "- customer_long has 10 missing values.\n",
    "- Using the formula whic has been defined under haversine_lon, we can impute the missing values for customer_lon.\n",
    "- It requires the distance bettwen customer and warehouse which has been defined by distance_to_nearest_warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_lon(dist, lat1, lat2, lon2):\n",
    "    #lat1, lon2 = customer's coordinates\n",
    "    # lat2, lon2 = warehouse's coordinates\n",
    "    radius = 6378\n",
    "    \n",
    "    x_squa = math.tan(dist / radius / 2) ** 2\n",
    "    top = x_squa * ((x_squa / (1 + x_squa) - math.sin(math.radians(lat1 - lat2) / 2) ** 2) ** 2)\n",
    "    bot = math.cos(math.radians(lat2)) * math.cos(math.radians(lat1))\n",
    "    \n",
    "    s1 = round(2 * math.asin(math.sqrt(top/bot)) / math.pi * 180 + lon2, 7)\n",
    "    s2 = round(2 * math.asin(- math.sqrt(top/bot)) / math.pi * 180 + lon2, 7)\n",
    "    \n",
    "    return s1, s2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the indices of row which has missing values in customer_long column\n",
    "null_lon = missing_file[missing_file['customer_long'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in null_lon:\n",
    "    j = missing_file.loc[i]\n",
    "    #finding the customer_lon using distance-to_nearest_warehouse, customer_lat, warehouse's lat, warehouse's lon\n",
    "    lon_cal = haversine_lon(j.distance_to_nearest_warehouse, j.customer_lat, warehouse_latlong[j.nearest_warehouse][0], warehouse_latlong[j.nearest_warehouse][1])\n",
    "    missing_file.loc[i, \"customer_long\"] = lon_cal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "bp = missing_file.boxplot(column = 'customer_long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the missing values in this column\n",
    "missing_file.customer_long.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing the missing values of order_price\n",
    "- order_price has 10 missing values.\n",
    "- order_price is dependent upon order_total, delivery_charges and coupon_discount.\n",
    "- By formulating an equation, we can impute the missing values for order_price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file.order_price.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the indices of row which has missing values in order_price column\n",
    "null_price = missing_file[missing_file['order_price'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in null_price:\n",
    "    j = missing_file.loc[i]\n",
    "    price = (j['order_total'] + j['delivery_charges']) / ((100 - j['coupon_discount'])/100) \n",
    "    missing_file.loc[i, 'order_price'] = price\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "missing_file['order_price'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the missing values in this column\n",
    "missing_file.order_price.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing the missing values of order_total\n",
    "- order_total has 10 missing values.\n",
    "- order_total depends upon order_price which may be discounted using coupon_discount and then delivery_charges are added in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file.order_total.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the indices of row which has missing values in order_total column\n",
    "null_total = missing_file[missing_file['order_total'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in null_total:\n",
    "    j = missing_file.loc[i]\n",
    "    price = (j['order_price']  * ((100 - j['coupon_discount'])/100)) + j['delivery_charges']\n",
    "    missing_file.loc[i, 'order_total'] = price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "missing_file['order_total'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the missing values in this column\n",
    "missing_file.order_total.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing the values of is_happy_customer\n",
    "- is_happy_customer has 10 missing values.\n",
    "- Using nltk library's, SentimentIntensityAnalyzer tool we can interpret the text and find its polarity, which are positive, negative, neutral and compound.\n",
    "- In the texts, whose compound value is more than and equal to \"0.05\" is considered True and remaining False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the indices of row which has missing values in is_happy_customer column\n",
    "null_val = missing_file[missing_file['is_happy_customer'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in null_val:\n",
    "    j = missing_file.loc[i]\n",
    "    review = j.latest_customer_review\n",
    "    senti_review = senti.polarity_scores(review)\n",
    "    temp = senti_review['compound']\n",
    "    if temp >= 0.05:\n",
    "        missing_file.loc[i,'is_happy_customer'] = True\n",
    "    elif temp < 0.05:\n",
    "        missing_file.loc[i,'is_happy_customer'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file.is_happy_customer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the missing values in this column\n",
    "missing_file.is_happy_customer.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the missing values in this file\n",
    "missing_file.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file.to_csv(r'./31901611_missing_data_solution.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the missing_data.csv, it included the coverage anomaly in eight columns. The columns in the file depend upon each other. With that inter-dependency, values has been imputed in missing columns. And a new 31901611_missing_data_solution.csv has been created."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
